{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38796c0",
   "metadata": {},
   "source": [
    "# Luantick Benchmark Example\n",
    "\n",
    "This example notebook provides a comprehensive example of how to use the Yardstick benchmark framework to collect performance metrics from Luanti game servers and evaluate their performance under bot load."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14538853",
   "metadata": {},
   "source": [
    "## Running a Luanti Experiment\n",
    "\n",
    "The cell below shows you how to run a Luanti server performance experiment using the DAS cluster. This deploys a Luanti server on one node and WalkAround bots on another node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yardstick_benchmark.provisioning import Das\n",
    "from yardstick_benchmark.monitoring import Telegraf\n",
    "from yardstick_benchmark.games.luanti.server import LuantiServer\n",
    "from yardstick_benchmark.games.luanti.workload import RustWalkAround\n",
    "import yardstick_benchmark\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set up output directory\n",
    "dest = Path(f\"/var/scratch/{os.getlogin()}/yardstick/luanti_output\")\n",
    "if dest.exists():\n",
    "    shutil.rmtree(dest)\n",
    "\n",
    "### DEPLOYMENT ENVIRONMENT ###\n",
    "\n",
    "# The DAS compute cluster is used to provision bare-metal machines\n",
    "# for our Luanti performance evaluation.\n",
    "das = Das()\n",
    "# We reserve 2 nodes - one for the Luanti server, one for bots.\n",
    "nodes = das.provision(num=2)\n",
    "\n",
    "try:\n",
    "    # Clean up any data from previous runs\n",
    "    yardstick_benchmark.clean(nodes)\n",
    "\n",
    "    ### METRICS ###\n",
    "\n",
    "    # Telegraf collects performance metrics from the nodes and applications\n",
    "    telegraf = Telegraf(nodes)\n",
    "    # Configure metrics collection for the Luanti server on node 0\n",
    "    telegraf.add_input_jolokia_agent(nodes[0])\n",
    "    \n",
    "    # Deploy and start Telegraf\n",
    "    res = telegraf.deploy()\n",
    "    telegraf.start()\n",
    "\n",
    "    ### LUANTI SERVER ###\n",
    "\n",
    "    # Deploy Luanti server on node 0\n",
    "    luanti_server = LuantiServer(nodes[:1], game_mode=\"minetest_game\")\n",
    "    luanti_server.deploy()\n",
    "    luanti_server.start()\n",
    "\n",
    "    ### WORKLOAD - RUST WALKBOTS ###\n",
    "\n",
    "    # Deploy RustWalkAround bots (from texmodbot) on node 1, connecting to server on node 0\n",
    "    # These are the Rust-based bots that actually work with the Luanti protocol\n",
    "    wl = RustWalkAround(\n",
    "        nodes[1:],              # Bots on node 1\n",
    "        nodes[0].host,          # Server on node 0\n",
    "        duration=timedelta(seconds=120),  # 2 minute test\n",
    "        bots_per_node=15,       # 15 concurrent bots\n",
    "        movement_mode=\"random\", # Random movement pattern\n",
    "        movement_speed=2.0,     # Change direction every 2 seconds\n",
    "    )\n",
    "    wl.deploy()\n",
    "    wl.start()\n",
    "\n",
    "    # Run the benchmark\n",
    "    sleep_time = 150\n",
    "    print(f\"Running Luanti benchmark for {sleep_time} seconds\")\n",
    "    print(f\"Server: {nodes[0].host}, Rust Bots: {nodes[1].host}\")\n",
    "    sleep(sleep_time)\n",
    "\n",
    "    # Cleanup\n",
    "    wl.stop()\n",
    "    wl.cleanup()\n",
    "    luanti_server.stop()\n",
    "    luanti_server.cleanup()\n",
    "    telegraf.stop()\n",
    "    telegraf.cleanup()\n",
    "\n",
    "    # Fetch results\n",
    "    yardstick_benchmark.fetch(dest, nodes)\n",
    "    print(f\"Results saved to: {dest}\")\n",
    "    \n",
    "finally:\n",
    "    yardstick_benchmark.clean(nodes)\n",
    "    das.release(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e5328",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Process the collected metrics data by splitting the combined CSV files into separate files for each metric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Find all metrics files from the experiment\n",
    "raw_data_files = glob.glob(f\"{dest}/**/metrics-*.csv\", recursive=True)\n",
    "print(f\"Found {len(raw_data_files)} metrics files:\")\n",
    "for f in raw_data_files:\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "# Split combined metrics files into separate files per metric type\n",
    "for raw_data_file in raw_data_files:\n",
    "    metrics_file = Path(raw_data_file)\n",
    "    keys = {}\n",
    "    with open(metrics_file) as fin:\n",
    "        for line in fin:\n",
    "            first_delim = line.find(\",\")\n",
    "            second_delim = line.find(\",\", first_delim+1)\n",
    "            key = line[first_delim+1:second_delim]\n",
    "            if key not in keys:\n",
    "                keys[key] = open(metrics_file.parent / f\"{key}.csv\", \"w+\")\n",
    "            keys[key].write(line)\n",
    "    for key, fd in keys.items():\n",
    "        fd.close()\n",
    "    print(f\"Split {metrics_file.name} into {len(keys)} metric files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436262b",
   "metadata": {},
   "source": [
    "## Visualizing Luanti Performance Results\n",
    "\n",
    "Analyze and visualize the performance data collected during the Luanti benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38258949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and process CPU utilization data\n",
    "dfs = []\n",
    "for cpu_file in glob.glob(f\"{dest}/**/cpu.csv\", recursive=True):\n",
    "    df = pd.read_csv(cpu_file, names=[\"timestamp\",\"measurement\",\"core_id\",\"cpu\",\"host\",\"physical_id\",\"time_active\",\"time_guest\",\"time_guest_nice\",\"time_idle\",\"time_iowait\",\"time_irq\",\"time_nice\",\"time_softirq\",\"time_steal\",\"time_system\",\"time_user\"])\n",
    "    df[\"node\"] = Path(cpu_file).parent.parent.name\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].transform(lambda x: x - x.min())\n",
    "    df[\"timestamp_m\"] = df[\"timestamp\"] / 60\n",
    "    df = df[df.cpu == \"cpu-total\"]\n",
    "    df['time_total'] = df.time_active + df.time_idle\n",
    "    df['util'] = 100 * df.time_active / df.time_total\n",
    "    df = df.sort_values(\"util\", ascending=False).drop_duplicates(subset=[\"timestamp\", \"cpu\"], keep=\"first\")\n",
    "    dfs.append(df)\n",
    "\n",
    "if dfs:\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Create CPU utilization plot\n",
    "    custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "    sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.lineplot(df, x=\"timestamp_m\", y=\"util\", hue=\"node\")\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_ylabel(\"CPU utilization [%]\")\n",
    "    ax.set_xlabel(\"Time [minutes]\")\n",
    "    ax.set_title(\"Luanti Server & Bot CPU Utilization\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nCPU Statistics:\")\n",
    "    print(df.groupby('node')['util'].agg(['mean', 'max', 'std']).round(2))\n",
    "else:\n",
    "    print(\"No CPU data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d70418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize memory utilization\n",
    "mem_files = glob.glob(f\"{dest}/**/mem.csv\", recursive=True)\n",
    "if mem_files:\n",
    "    mem_dfs = []\n",
    "    for mem_file in mem_files:\n",
    "        df = pd.read_csv(mem_file)\n",
    "        df[\"node\"] = Path(mem_file).parent.parent.name\n",
    "        df[\"timestamp\"] = df[\"timestamp\"].transform(lambda x: x - x.min())\n",
    "        df[\"timestamp_m\"] = df[\"timestamp\"] / 60\n",
    "        # Calculate memory utilization percentage\n",
    "        if 'used_percent' in df.columns:\n",
    "            mem_dfs.append(df)\n",
    "    \n",
    "    if mem_dfs:\n",
    "        mem_df = pd.concat(mem_dfs, ignore_index=True)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.lineplot(mem_df, x=\"timestamp_m\", y=\"used_percent\", hue=\"node\")\n",
    "        ax.grid(axis=\"y\")\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.set_ylabel(\"Memory utilization [%]\")\n",
    "        ax.set_xlabel(\"Time [minutes]\")\n",
    "        ax.set_title(\"Luanti Server & Bot Memory Usage\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nMemory Statistics:\")\n",
    "        print(mem_df.groupby('node')['used_percent'].agg(['mean', 'max', 'std']).round(2))\n",
    "else:\n",
    "    print(\"No memory data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d69b7d",
   "metadata": {},
   "source": [
    "## Benchmark Summary\n",
    "\n",
    "This benchmark demonstrates the performance characteristics of Luanti servers under bot load. Key insights:\n",
    "\n",
    "- **CPU Usage**: Shows how the server handles concurrent bot connections and movement\n",
    "- **Memory Usage**: Indicates memory consumption patterns for world simulation  \n",
    "- **Network Traffic**: Reveals protocol overhead and bandwidth requirements\n",
    "\n",
    "The separation of server and bots onto different nodes allows for clear analysis of where computational bottlenecks occur in the Luanti architecture."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
